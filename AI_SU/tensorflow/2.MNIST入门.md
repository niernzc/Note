```python
x = tf.placeholder("float",[None,784])
```

创建一个可交互的操作单元，x不是一个特定的值，而实一个占位符，在运行计算时输入这个值。当希望输入任意数量的MNIST图像时，每张图展平成784维的向量。使用2维浮点数张量来表示这些图，该张量的形状是[None,784].None表示第一维的长度可以是任意的。(第一维度-列数；第二维度-行数；…)

```python
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
```

模型需要权重值和偏置值，tf使用variable来表示它们。一个variable表示一个可以修改的张量。这里使用全零的张量来初始化

```python
y = tf.nn.softmax(tf.matmul(x,W) + b)
```

等价于$y=softmax(Wx+b)$。

### 训练模型

目标：将loss最小化

loss的一个定义：**交叉熵**：$H_{y'}(y) = -\sum_{i} y'*log(y_i)$ 

添加一个新的占位符用于输入正确值：

```python
y_ = tf.placeholder("float", [None,10])
```

计算交叉熵：

```python
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
```

reduce_sum为求和操作

```python
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
```

采用梯度下降法降低交叉熵

当前模型已经设置好，运行计算之前，需要先添加一个操作来初始化创建的变量：

```python
init = tf.initialize_all_variables()
```

在一个`Session`中启动模型，并且初始化变量：

```python
sess = tf.Session()
sess.run(init)
```

训练模型：

```python
for i in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
```

该循环的每个步骤中，都会随机抓取训练数据中的100个批处理数据点，然后用这些数据点作为参数替换之前的占位符来运行`train_step` 

### 评估模型

首先找出预测正确的标签。在这里标签是由0，1组成的向量，使用`tf.argmax`函数来获得其数据最大值所在的索引，使用`tf.equal`来检测预测是否和真实标签匹配

```python
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
```

该行代码获得一组布尔值，为了确定正确的比例，可以将布尔值换成浮点数，然后取平均值：

```python
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
```

最后计算学习到的模型在测试数据集上的正确率：

```python
print sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})
```

